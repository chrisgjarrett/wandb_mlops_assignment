{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/mlops-001/lesson1/03_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{course-lesson1} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4723ae62-c55d-4c8f-9157-43c29189a2ff",
   "metadata": {},
   "source": [
    "# Baseline solution\n",
    "\n",
    "<!--- @wandbcode{course-lesson1} -->\n",
    "\n",
    "In this notebook we will create a baseline solution to our semantic segmentation problem. To iterate fast a notebook is a handy solution. We will then refactor this code into a script to be able to use hyperparameter sweeps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29116dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from utils import get_predictions, create_predictions_table\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score \n",
    "import params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0871e5-c07d-4a8b-817b-388c2e9bf7d1",
   "metadata": {},
   "source": [
    "Again, we're importing some global configuration parameters from `params.py` file. We have also defined some helper functions in `utils.py` - for example metrics we will track during our experiments.\n",
    "\n",
    "Let's now create a `train_config` that we'll pass to W&B `run` to control training hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff6b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = SimpleNamespace(\n",
    "    framework=\"fastai\",\n",
    "    img_size=(18, 32),\n",
    "    batch_size=1024,\n",
    "    augment=True, # use data augmentation\n",
    "    epochs=5, \n",
    "    lr=2e-3,\n",
    "    pretrained=True,  # whether to use pretrained encoder\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f014f3-d78f-4f5b-b038-d8020de43930",
   "metadata": {},
   "source": [
    "We are setting seed for reproducibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc6765f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(train_config.seed, reproducible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32483e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchrisgjarrett\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/chrisjarrett/Documents/Personal/Data Projects/wandb_mlops_assignment/wandb/run-20230305_180015-bver8w5s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/chrisgjarrett/mlops-course-assignment/runs/bver8w5s' target=\"_blank\">glorious-gorge-88</a></strong> to <a href='https://wandb.ai/chrisgjarrett/mlops-course-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/chrisgjarrett/mlops-course-assignment' target=\"_blank\">https://wandb.ai/chrisgjarrett/mlops-course-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/chrisgjarrett/mlops-course-assignment/runs/bver8w5s' target=\"_blank\">https://wandb.ai/chrisgjarrett/mlops-course-assignment/runs/bver8w5s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=params.WANDB_PROJECT, entity=params.ENTITY, job_type=\"training\", config=train_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7c1872-fc08-4304-9842-203d9ac45371",
   "metadata": {},
   "source": [
    "As usual, we will use W&B Artifacts to track the lineage of our models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df839467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact processed_data_at:latest, 556.40MB. 8619 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   8619 of 8619 files downloaded.  \n",
      "Done. 0:0:0.7\n"
     ]
    }
   ],
   "source": [
    "processed_data_at = run.use_artifact(f'{params.PROCESSED_DATA_AT}:latest')\n",
    "processed_dataset_dir = Path(processed_data_at.download())\n",
    "df = pd.read_csv(processed_dataset_dir / 'data_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "771fd02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6) [Path('artifacts/processed_data_at:v6/t2_11115475104.table.json'),Path('artifacts/processed_data_at:v6/images'),Path('artifacts/processed_data_at:v6/data_split.csv'),Path('artifacts/processed_data_at:v6/eda_table_data_split.joined-table.json'),Path('artifacts/processed_data_at:v6/eda_table.table.json'),Path('artifacts/processed_data_at:v6/media')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset_dir.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77170345-96d3-4371-a4e9-5ea3b15e2cdb",
   "metadata": {},
   "source": [
    "We will not use the hold out dataset stage at this moment. `is_valid` column will tell our trainer how we want to split data between training and validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a34e1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread SystemMonitor:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/wandb_course/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/wandb_course/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/wandb_course/lib/python3.8/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 118, in _start\n",
      "    asset.start()\n",
      "  File \"/opt/miniconda3/envs/wandb_course/lib/python3.8/site-packages/wandb/sdk/internal/system/assets/cpu.py\", line 166, in start\n",
      "    self.metrics_monitor.start()\n",
      "  File \"/opt/miniconda3/envs/wandb_course/lib/python3.8/site-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 168, in start\n",
      "    logger.info(f\"Started {self._process.name}\")\n",
      "AttributeError: 'NoneType' object has no attribute 'name'\n"
     ]
    }
   ],
   "source": [
    "df = df[df.Stage != 'test'].reset_index(drop=True)\n",
    "df['is_valid'] = df.Stage == 'valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65ae3d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(fname):\n",
    "    return \"Not Cancer\" in fname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fb25d8-50b0-4c14-9d52-d14725e024c9",
   "metadata": {},
   "source": [
    "We will use `fastai`'s `DataBlock` API to feed data into model training and validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f713864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign paths\n",
    "df[\"image_fname\"] = [processed_dataset_dir/f'images/{f}' for f in df.Filename.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91e4dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "929d999b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6) [Path('artifacts/processed_data_at:v6/t2_11115475104.table.json'),Path('artifacts/processed_data_at:v6/images'),Path('artifacts/processed_data_at:v6/data_split.csv'),Path('artifacts/processed_data_at:v6/eda_table_data_split.joined-table.json'),Path('artifacts/processed_data_at:v6/eda_table.table.json'),Path('artifacts/processed_data_at:v6/media')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset_dir.ls()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4268334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df:pd.DataFrame, bs=1, img_size=(180, 320), augment=True):\n",
    "    block = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                  get_x=ColReader(0, pref=processed_dataset_dir/\"images\"),\n",
    "                  get_y=ColReader(\"Class\"),\n",
    "                  splitter=ColSplitter(),\n",
    "                  item_tfms=Resize(img_size),\n",
    "                #   batch_tfms=aug_transforms() if augment else None,                 )\n",
    "            )\n",
    "    return block.dataloaders(df, bs=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929f7975-ff29-4692-89b3-7f7596aecb0a",
   "metadata": {},
   "source": [
    "We are using `wandb.config` to track our training hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f214f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58544078",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_data(df, bs=train_config.batch_size, img_size=train_config.img_size, augment=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9fd4610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/wandb_course/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/wandb_course/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "metrics = [F1Score(), BalancedAccuracy()]\n",
    "\n",
    "learn = vision_learner(dls, models.resnet34, metrics = metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d45330-cfc2-44e9-8c0c-5eee417050b1",
   "metadata": {},
   "source": [
    "In `fastai` we already have a callback that integrates tightly with W&B, we only need to pass the `WandbCallback` to the learner and we are ready to go. The callback will log all the useful variables for us. For example, whatever metric we pass to the learner will be tracked by the callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87db7e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    SaveModelCallback(monitor='f1_score'),\n",
    "    WandbCallback(log_preds=False, log_model=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfe3c60-f4af-4e21-874d-13f119d03dd5",
   "metadata": {},
   "source": [
    "Let's train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1846493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with f1_score value: 0.7412587412587412.\n",
      "Better model found at epoch 4 with f1_score value: 0.767932489451477.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(train_config.epochs, train_config.lr, cbs=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976ac11f-ad6c-4f9d-b2b0-6acb8d7af34a",
   "metadata": {},
   "source": [
    "We will log a table with model predictions and ground truth to W&B, so that we can do error analysis in the W&B dashboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "387dc2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, predictions = get_predictions(learn)\n",
    "table = create_predictions_table(samples, predictions)\n",
    "wandb.log({\"pred_table\":table})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b913a7ca-1250-4a61-a011-d333110bb927",
   "metadata": {},
   "source": [
    "We are reloading the model from the best checkpoint at the end and saving it. To make sure we track the final metrics correctly, we will validate the model again and save the final loss and metrics to `wandb.summary`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6ec120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = learn.validate()\n",
    "metric_names = ['final_loss'] + [f'final_{x.name}' for x in metrics]\n",
    "final_results = {metric_names[i] : scores[i] for i in range(len(scores))}\n",
    "for k,v in final_results.items(): \n",
    "    wandb.summary[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53f86720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>balanced_accuracy_score</td><td>▁▃▆▇█</td></tr><tr><td>epoch</td><td>▁▂▂▃▃▃▄▅▅▅▆▆▇▇█</td></tr><tr><td>eps_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eps_1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eps_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▇▁▅▇█</td></tr><tr><td>lr_0</td><td>▁▂▅▇██▇▇▆▅▄▃▂▁▁</td></tr><tr><td>lr_1</td><td>▁▂▅▇██▇▇▆▅▄▃▂▁▁</td></tr><tr><td>lr_2</td><td>▁▂▅▇██▇▇▆▅▄▃▂▁▁</td></tr><tr><td>mom_0</td><td>█▇▄▂▁▁▂▂▃▄▅▆▇▇█</td></tr><tr><td>mom_1</td><td>█▇▄▂▁▁▂▂▃▄▅▆▇▇█</td></tr><tr><td>mom_2</td><td>█▇▄▂▁▁▂▂▃▄▅▆▇▇█</td></tr><tr><td>raw_loss</td><td>██▇▅▃▃▃▃▃▁▁▂▁▂▁</td></tr><tr><td>sqr_mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sqr_mom_1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sqr_mom_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>██▇▇▅▄▄▃▃▃▂▂▁▁▁</td></tr><tr><td>train_samples_per_sec</td><td>▁████████▇██▇▇▇</td></tr><tr><td>valid_loss</td><td>▂█▃▁▁</td></tr><tr><td>wd_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>wd_1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>wd_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>balanced_accuracy_score</td><td>0.76446</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>eps_0</td><td>1e-05</td></tr><tr><td>eps_1</td><td>1e-05</td></tr><tr><td>eps_2</td><td>1e-05</td></tr><tr><td>f1_score</td><td>0.76793</td></tr><tr><td>final_balanced_accuracy_score</td><td>0.76446</td></tr><tr><td>final_f1_score</td><td>0.76793</td></tr><tr><td>final_loss</td><td>0.65247</td></tr><tr><td>lr_0</td><td>4e-05</td></tr><tr><td>lr_1</td><td>4e-05</td></tr><tr><td>lr_2</td><td>4e-05</td></tr><tr><td>mom_0</td><td>0.94806</td></tr><tr><td>mom_1</td><td>0.94806</td></tr><tr><td>mom_2</td><td>0.94806</td></tr><tr><td>raw_loss</td><td>0.69839</td></tr><tr><td>sqr_mom_0</td><td>0.99</td></tr><tr><td>sqr_mom_1</td><td>0.99</td></tr><tr><td>sqr_mom_2</td><td>0.99</td></tr><tr><td>train_loss</td><td>0.84227</td></tr><tr><td>train_samples_per_sec</td><td>3389.38544</td></tr><tr><td>valid_loss</td><td>0.65247</td></tr><tr><td>wd_0</td><td>0.01</td></tr><tr><td>wd_1</td><td>0.01</td></tr><tr><td>wd_2</td><td>0.01</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glorious-gorge-88</strong> at: <a href='https://wandb.ai/chrisgjarrett/mlops-course-assignment/runs/bver8w5s' target=\"_blank\">https://wandb.ai/chrisgjarrett/mlops-course-assignment/runs/bver8w5s</a><br/>Synced 6 W&B file(s), 1 media file(s), 452 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230305_180015-bver8w5s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wandb_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "32b693ab92d819577db481632b0f8d060b4e49b728e66429591a1167cf08cfc8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
